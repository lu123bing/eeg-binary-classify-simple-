import pytorch_lightning as pl
from torch.utils.data import DataLoader
from data_loader import create_binary_datasets
import torch

class EEGBinaryDataModule(pl.LightningDataModule):
    """EEGäºŒåˆ†ç±»æ•°æ®æ¨¡å— - ä¼˜åŒ–ç‰ˆ"""
    
    def __init__(self, data_cfg, train_subs, val_subs, train_vids, val_vids, 
                 loo, num_workers):
        super().__init__()
        
        self.data_cfg = data_cfg
        self.train_subs = train_subs
        self.val_subs = val_subs
        self.train_vids = train_vids
        self.val_vids = val_vids
        self.loo = loo
        self.num_workers = num_workers
        
        # ğŸ”¥ ç¼“å­˜æ•°æ®é›†ï¼Œé¿å…é‡å¤åŠ è½½
        self._train_dataset = None
        self._val_dataset = None
        self._test_dataset = None
        
        print(f"ğŸ“‚ EEGäºŒåˆ†ç±»æ•°æ®æ¨¡å—åˆå§‹åŒ– (ä¼˜åŒ–ç‰ˆ):")
        print(f"   è®­ç»ƒè¢«è¯•: {len(train_subs) if train_subs else 0}")
        print(f"   éªŒè¯è¢«è¯•: {len(val_subs) if val_subs else 0}")
        print(f"   å·¥ä½œè¿›ç¨‹: {num_workers}")
        
    def setup(self, stage=None):
        """è®¾ç½®æ•°æ®é›† - åªåŠ è½½ä¸€æ¬¡"""
        if self._train_dataset is not None:
            print("ğŸ“¦ ä½¿ç”¨ç¼“å­˜çš„æ•°æ®é›†")
            return
            
        print(f"ğŸ”§ æ•°æ®æ¨¡å—è®¾ç½®é˜¶æ®µ: {stage}")
        
        # åŠ è½½æ•°æ®...
        self._train_dataset, self._val_dataset, self._test_dataset = create_binary_datasets(
            data_dir=self.data_cfg.data_dir,
            train_subs=self.train_subs,
            val_subs=self.val_subs,
            max_samples=getattr(self.data_cfg, 'max_samples', None),
            n_channels=self.data_cfg.n_channels,
            n_timepoints=self.data_cfg.n_timepoints,
        )
        
        # ğŸ”¥ æ•°æ®è´¨é‡æ£€æŸ¥
        print(f"ğŸ“Š æ•°æ®è´¨é‡åˆ†æ:")
        
        # æ£€æŸ¥è®­ç»ƒæ•°æ®
        train_data_tensor = self._train_dataset.data
        train_labels_tensor = self._train_dataset.labels
        
        print(f"   è®­ç»ƒæ•°æ®å½¢çŠ¶: {train_data_tensor.shape}")
        # print(f"   æ•°æ®ç±»å‹: {train_data_tensor.dtype}")
        print(f"   æ•°æ®èŒƒå›´: [{train_data_tensor.min():.3f}, {train_data_tensor.max():.3f}, æ•°æ®å‡å€¼: {train_data_tensor.mean():.3f}]")
        # print(f"   æ•°æ®å‡å€¼: {train_data_tensor.mean():.3f}")
        # print(f"   æ•°æ®æ ‡å‡†å·®: {train_data_tensor.std():.3f}")
        
        # ğŸ”¥ æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ ·æœ¬éƒ½ç›¸åŒ
        first_sample = train_data_tensor[0]
        all_same = True
        for i in range(min(10, len(train_data_tensor))):
            if not torch.allclose(train_data_tensor[i], first_sample, rtol=1e-3):
                all_same = False
                break
        
        if all_same:
            print("âš ï¸ è­¦å‘Šï¼šå‰10ä¸ªæ ·æœ¬å‡ ä¹ç›¸åŒï¼æ•°æ®å¯èƒ½æœ‰é—®é¢˜")
        else:
            print("âœ… æ ·æœ¬é—´å­˜åœ¨å·®å¼‚")
        
        # ğŸ”¥ æŒ‰ç±»åˆ«æ£€æŸ¥æ•°æ®å·®å¼‚
        pos_indices = train_labels_tensor == 1
        neg_indices = train_labels_tensor == 0
        
        if pos_indices.any() and neg_indices.any():
            pos_data = train_data_tensor[pos_indices]
            neg_data = train_data_tensor[neg_indices]
            
            pos_mean = pos_data.mean()
            neg_mean = neg_data.mean()
            
            print(f"   æ­£æ ·æœ¬å‡å€¼: {pos_mean:.3f},è´Ÿæ ·æœ¬å‡å€¼: {neg_mean:.3f}")
            print(f"   ç±»åˆ«é—´å·®å¼‚: {abs(pos_mean - neg_mean):.3f}")
            
            if abs(pos_mean - neg_mean) < 0.01:
                print("âš ï¸ è­¦å‘Šï¼šæ­£è´Ÿæ ·æœ¬å‡ ä¹æ— å·®å¼‚ï¼")
            else:
                print("âœ… æ­£è´Ÿæ ·æœ¬å­˜åœ¨å·®å¼‚")
        
        print(f"âœ… æ•°æ®é›†è®¾ç½®å®Œæˆ:")
        print(f"   è®­ç»ƒé›†: {len(self._train_dataset)}")
        print(f"   éªŒè¯é›†: {len(self._val_dataset)},æµ‹è¯•é›†: {len(self._test_dataset)}")
    
    @property
    def train_dataset(self):
        return self._train_dataset
    
    @property 
    def val_dataset(self):
        return self._val_dataset
        
    @property
    def test_dataset(self):
        return self._test_dataset
    
    def train_dataloader(self):
        # ğŸ”¥ ä¼˜åŒ–DataLoaderè®¾ç½®
        return DataLoader(
            self.train_dataset,
            batch_size=self.data_cfg.batch_size,
            shuffle=True,
            num_workers=min(self.num_workers, 4),  # ğŸ”¥ é™åˆ¶workeræ•°é‡
            pin_memory=torch.cuda.is_available(),
            persistent_workers=True if self.num_workers > 0 else False,  # ğŸ”¥ ä¿æŒworkerå­˜æ´»
            prefetch_factor=2 if self.num_workers > 0 else None,  # ğŸ”¥ é¢„å–æ•°æ®
            drop_last=True  # ğŸ”¥ ä¸¢å¼ƒä¸å®Œæ•´çš„æ‰¹æ¬¡
        )
    
    def val_dataloader(self):
        return DataLoader(
            self.val_dataset,
            batch_size=self.data_cfg.batch_size,
            shuffle=True,
            num_workers=min(self.num_workers, 2),  # ğŸ”¥ éªŒè¯æ—¶ç”¨æ›´å°‘worker
            pin_memory=torch.cuda.is_available(),
            persistent_workers=True if self.num_workers > 0 else False,
            prefetch_factor=2 if self.num_workers > 0 else None
        )
    
    def test_dataloader(self):
        return DataLoader(
            self.test_dataset,
            batch_size=self.data_cfg.batch_size,
            shuffle=True,
            num_workers=0,  # ğŸ”¥ æµ‹è¯•æ—¶ä¸ç”¨å¤šè¿›ç¨‹
            pin_memory=torch.cuda.is_available()
        )

# ä¿æŒä¸ä¸»é¡¹ç›®ä¸€è‡´çš„å‘½å
EEGDataModule = EEGBinaryDataModule
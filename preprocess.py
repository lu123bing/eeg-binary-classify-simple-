import os
import scipy.io as sio
import numpy as np
import pickle
from tqdm import tqdm

def preprocess_eeg_data():
    """
    ä»åŸå§‹.matæ–‡ä»¶ä¸­æå–æ¯ä¸ªè§†é¢‘çš„æœ€åä¸€ç§’EEGæ•°æ®å¹¶æ‰“æ ‡ç­¾
    """
    
    # ğŸ”¥ é…ç½®è·¯å¾„
    raw_data_dir = r"E:\PyCharm Community Edition 2023.2.1\path\pypj\DAEST-main\processed_data"
    output_dir = r"E:\PyCharm Community Edition 2023.2.1\path\pypj\DAEST-main\sliced_data_1s"
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # ğŸ”¥ ä¿®æ­£çš„è§†é¢‘æ ‡ç­¾æ˜ å°„ - å»é™¤ä¸­æ€§è§†é¢‘åçš„æ–°ç´¢å¼•
    # æ³¨æ„ï¼šmatæ–‡ä»¶ä¸­çš„ç´¢å¼•ä»0å¼€å§‹ï¼Œæ‰€ä»¥è¦å‡1
    video_labels = {
        # è´Ÿé¢æƒ…ç»ª -> 0 (åŸè§†é¢‘1-12ï¼Œç°åœ¨æ˜¯ç´¢å¼•0-11)
        0: 0, 1: 0, 2: 0,      # æ„¤æ€’ (åŸè§†é¢‘1-3)
        3: 0, 4: 0, 5: 0,      # åŒæ¶ (åŸè§†é¢‘4-6)
        6: 0, 7: 0, 8: 0,      # ææƒ§ (åŸè§†é¢‘7-9)
        9: 0, 10: 0, 11: 0,    # æ‚²ä¼¤ (åŸè§†é¢‘10-12)
        
        # æ­£é¢æƒ…ç»ª -> 1 (åŸè§†é¢‘17-28ï¼Œç°åœ¨æ˜¯ç´¢å¼•12-23)
        12: 1, 13: 1, 14: 1,   # å¨±ä¹ (åŸè§†é¢‘17-19)
        15: 1, 16: 1, 17: 1,   # æ¿€åŠ± (åŸè§†é¢‘20-22)
        18: 1, 19: 1, 20: 1,   # å¿«ä¹ (åŸè§†é¢‘23-25)
        21: 1, 22: 1, 23: 1,   # æ¸©æŸ” (åŸè§†é¢‘26-28)
    }
    
    # ğŸ”¥ åŸå§‹è§†é¢‘IDåˆ°æ–°ç´¢å¼•çš„æ˜ å°„ï¼ˆç”¨äºæ–‡ä»¶åï¼‰
    original_video_mapping = {
        0: 1, 1: 2, 2: 3,      # æ„¤æ€’
        3: 4, 4: 5, 5: 6,      # åŒæ¶
        6: 7, 7: 8, 8: 9,      # ææƒ§
        9: 10, 10: 11, 11: 12, # æ‚²ä¼¤
        12: 17, 13: 18, 14: 19, # å¨±ä¹
        15: 20, 16: 21, 17: 22, # æ¿€åŠ±
        18: 23, 19: 24, 20: 25, # å¿«ä¹
        21: 26, 22: 27, 23: 28, # æ¸©æŸ”
    }
    
    print(f"ğŸ” æœç´¢åŸå§‹æ•°æ®ç›®å½•: {raw_data_dir}")
    
    # ğŸ”¥ æŸ¥æ‰¾æ‰€æœ‰.matæ–‡ä»¶
    mat_files = []
    for file in os.listdir(raw_data_dir):
        if file.endswith('.mat'):
            mat_files.append(os.path.join(raw_data_dir, file))
    
    print(f"ğŸ“‚ æ‰¾åˆ° {len(mat_files)} ä¸ª.matæ–‡ä»¶")
    
    if len(mat_files) == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°.matæ–‡ä»¶ï¼")
        return
    
    # ğŸ”¥ å¤„ç†æ¯ä¸ªè¢«è¯•çš„æ•°æ®
    metadata = {
        'subject_info': [],
        'video_info': [],
        'label_mapping': {0: 'negative', 1: 'positive'},
        'sampling_rate': 250,
        'duration': 1.0,  # æœ€å1ç§’
        'n_channels': 17,  # æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
        'n_videos': 24,    # å»é™¤ä¸­æ€§è§†é¢‘åå‰©ä½™24ä¸ª
        'video_mapping': original_video_mapping
    }
    
    total_samples = 0
    
    for mat_file in tqdm(mat_files, desc="å¤„ç†è¢«è¯•æ•°æ®"):
        try:
            # ğŸ”¥ åŠ è½½.matæ–‡ä»¶
            mat_data = sio.loadmat(mat_file)
            
            # æå–è¢«è¯•IDï¼ˆä»æ–‡ä»¶åï¼‰
            subject_id = extract_subject_id(mat_file)
            
            print(f"\nğŸ”„ å¤„ç†è¢«è¯• {subject_id}")
            print(f"ğŸ“ æ–‡ä»¶: {os.path.basename(mat_file)}")
            
            # ğŸ”¥ æ£€æŸ¥.matæ–‡ä»¶ç»“æ„
            print(f"ğŸ“Š .matæ–‡ä»¶é”®: {list(mat_data.keys())}")
            
            # ğŸ”¥ æ ¹æ®å®é™…çš„matæ–‡ä»¶ç»“æ„æå–æ•°æ®
            eeg_data = None
            n_samples_one = None
            binary_labels = None
            
            if 'data_all_cleaned' in mat_data:
                eeg_data = mat_data['data_all_cleaned']
                print(f"âœ… æ‰¾åˆ°EEGæ•°æ®: data_all_cleaned, å½¢çŠ¶={eeg_data.shape}")
            
            if 'n_samples_one' in mat_data:
                n_samples_one = mat_data['n_samples_one']
                print(f"âœ… æ‰¾åˆ°æ ·æœ¬æ•°ä¿¡æ¯: n_samples_one, å½¢çŠ¶={n_samples_one.shape}")
            
            if 'binary_labels' in mat_data:
                binary_labels = mat_data['binary_labels']
                print(f"âœ… æ‰¾åˆ°æ ‡ç­¾ä¿¡æ¯: binary_labels, å½¢çŠ¶={binary_labels.shape}")
            
            if eeg_data is None:
                print(f"âŒ æ— æ³•æ‰¾åˆ°EEGæ•°æ®ï¼Œè·³è¿‡æ–‡ä»¶: {mat_file}")
                continue
            
            # ğŸ”¥ è°ƒæ•´é€šé“æ•°ï¼ˆä»30é€šé“åˆ°17é€šé“ï¼‰
            if eeg_data.shape[0] == 30:
                # é€‰æ‹©å‰17ä¸ªé€šé“ï¼Œæˆ–è€…æ ¹æ®å®é™…éœ€è¦é€‰æ‹©ç‰¹å®šé€šé“
                eeg_data = eeg_data[:17, :]  # å–å‰17ä¸ªé€šé“
                print(f"ğŸ“Š è°ƒæ•´é€šé“æ•°: 30 -> 17, æ–°å½¢çŠ¶={eeg_data.shape}")
            
            # ğŸ”¥ æ ¹æ®æ•°æ®å½¢çŠ¶å’Œæ ·æœ¬æ•°ä¿¡æ¯ç»„ç»‡æ•°æ®
            video_data_list = organize_eeg_data(eeg_data, n_samples_one, expected_videos=24)
            
            if video_data_list is None:
                print(f"âŒ æ— æ³•è§£æEEGæ•°æ®ç»“æ„ï¼Œè·³è¿‡: {mat_file}")
                continue
            
            print(f"ğŸ“Š æˆåŠŸåˆ†å‰²å‡º {len(video_data_list)} ä¸ªè§†é¢‘")
            
            # ğŸ”¥ å¤„ç†æ¯ä¸ªè§†é¢‘ - ä½¿ç”¨æ–°çš„ç´¢å¼•
            for video_idx in video_labels.keys():
                try:
                    # æå–è¯¥è§†é¢‘çš„æ•°æ®
                    video_eeg = extract_video_data(video_data_list, video_idx)
                    
                    if video_eeg is None:
                        print(f"âš ï¸ è§†é¢‘ç´¢å¼• {video_idx} æ•°æ®æå–å¤±è´¥")
                        continue
                    
                    print(f"ğŸ“Š è§†é¢‘ {video_idx} åŸå§‹å½¢çŠ¶: {video_eeg.shape}")
                    
                    # ğŸ”¥ æå–æœ€åä¸€ç§’æ•°æ® (250Hz * 1ç§’ = 250ä¸ªæ—¶é—´ç‚¹)
                    sampling_rate = 250
                    last_second_points = sampling_rate * 1  # æœ€å1ç§’
                    
                    if video_eeg.shape[-1] < last_second_points:
                        print(f"âš ï¸ è§†é¢‘ç´¢å¼• {video_idx} æ•°æ®é•¿åº¦ä¸è¶³1ç§’: {video_eeg.shape[-1]} < {last_second_points}")
                        continue
                    
                    # æå–æœ€å1ç§’
                    last_second_eeg = video_eeg[:, -2*last_second_points:]
                    
                    # ç¡®ä¿å½¢çŠ¶ä¸º (17, 250)
                    if last_second_eeg.shape[0] != 17:
                        if last_second_eeg.shape[1] == 17:
                            last_second_eeg = last_second_eeg.T
                        else:
                            # è°ƒæ•´é€šé“æ•°
                            last_second_eeg = adjust_channels(last_second_eeg, target_channels=17)
                    
                    print(f"ğŸ“Š è§†é¢‘ {video_idx} æœ€å1ç§’å½¢çŠ¶: {last_second_eeg.shape}")
                    
                    # ğŸ”¥ è·å–æ ‡ç­¾å’ŒåŸå§‹è§†é¢‘ID
                    label = video_labels[video_idx]
                    original_video_id = original_video_mapping[video_idx]
                    
                    # ğŸ”¥ ä¿å­˜æ•°æ® - ä½¿ç”¨åŸå§‹è§†é¢‘IDå‘½åä»¥ä¿æŒä¸€è‡´æ€§
                    filename = f"sub{subject_id:03d}_vid{original_video_id:02d}_idx{video_idx:02d}_label{label}.pkl"
                    filepath = os.path.join(output_dir, filename)
                    
                    # ä¿å­˜ä¸ºpickleæ ¼å¼
                    data_dict = {
                        'eeg': last_second_eeg,
                        'label': label,
                        'subject_id': subject_id,
                        'video_idx': video_idx,  # æ–°çš„ç´¢å¼•ä½ç½®
                        'original_video_id': original_video_id,  # åŸå§‹è§†é¢‘ID
                        'emotion': get_emotion_name(video_idx),
                        'valence': 'positive' if label == 1 else 'negative'
                    }
                    
                    with open(filepath, 'wb') as f:
                        pickle.dump(data_dict, f)
                    
                    # ğŸ”¥ æ›´æ–°å…ƒæ•°æ®
                    metadata['video_info'].append({
                        'filename': filename,
                        'subject_id': subject_id,
                        'video_idx': video_idx,
                        'original_video_id': original_video_id,
                        'label': label,
                        'emotion': get_emotion_name(video_idx),
                        'shape': last_second_eeg.shape
                    })
                    
                    total_samples += 1
                    print(f"âœ… ä¿å­˜è§†é¢‘ {video_idx}: {filename}")
                    
                except Exception as e:
                    print(f"âš ï¸ å¤„ç†è§†é¢‘ç´¢å¼• {video_idx} æ—¶å‡ºé”™: {e}")
                    continue
            
            # ğŸ”¥ è®°å½•è¢«è¯•ä¿¡æ¯
            processed_videos = len([info for info in metadata['video_info'] if info['subject_id'] == subject_id])
            metadata['subject_info'].append({
                'subject_id': subject_id,
                'filename': os.path.basename(mat_file),
                'processed_videos': processed_videos
            })
            
            print(f"ğŸ“Š è¢«è¯• {subject_id} å¤„ç†å®Œæˆ: {processed_videos} ä¸ªè§†é¢‘")
            
        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶ {mat_file} æ—¶å‡ºé”™: {e}")
            continue
    
    # ğŸ”¥ ä¿å­˜å…ƒæ•°æ®
    metadata_file = os.path.join(output_dir, 'metadata.pkl')
    with open(metadata_file, 'wb') as f:
        pickle.dump(metadata, f)
    
    print(f"\nğŸ‰ æ•°æ®é¢„å¤„ç†å®Œæˆ!")
    print(f"ğŸ“Š å¤„ç†ç»“æœ:")
    print(f"   æ€»æ ·æœ¬æ•°: {total_samples}")
    print(f"   è¢«è¯•æ•°: {len(metadata['subject_info'])}")
    print(f"   è¾“å‡ºç›®å½•: {output_dir}")
    print(f"   å…ƒæ•°æ®æ–‡ä»¶: {metadata_file}")
    
    # ğŸ”¥ ç»Ÿè®¡æ ‡ç­¾åˆ†å¸ƒ
    labels = [info['label'] for info in metadata['video_info']]
    unique, counts = np.unique(labels, return_counts=True)
    print(f"   æ ‡ç­¾åˆ†å¸ƒ: {dict(zip(unique, counts))}")

def extract_subject_id(mat_file):
    """ä»æ–‡ä»¶åæå–è¢«è¯•ID"""
    filename = os.path.basename(mat_file)
    
    # å¸¸è§çš„è¢«è¯•IDæ¨¡å¼
    import re
    
    # æ¨¡å¼1: sub001.mat, subject_001.mat
    match = re.search(r'sub(?:ject)?[_-]?(\d+)', filename, re.IGNORECASE)
    if match:
        return int(match.group(1))
    
    # æ¨¡å¼2: 001.mat, 1.mat
    match = re.search(r'^(\d+)\.mat', filename)
    if match:
        return int(match.group(1))
    
    # æ¨¡å¼3: ä»»ä½•æ•°å­—
    match = re.search(r'(\d+)', filename)
    if match:
        return int(match.group(1))
    
    # é»˜è®¤ä½¿ç”¨æ–‡ä»¶åå“ˆå¸Œ
    return hash(filename) % 1000

def organize_eeg_data(eeg_data, n_samples_one=None, expected_videos=24):
    """ç»„ç»‡EEGæ•°æ®æ ¼å¼ - å¤„ç†2Dè¿ç»­æ•°æ®"""
    
    print(f"ğŸ“Š ç»„ç»‡EEGæ•°æ®ï¼ŒåŸå§‹å½¢çŠ¶: {eeg_data.shape}")
    
    if eeg_data.ndim == 2:
        # 2Dæ•°æ®: (channels, timepoints)
        n_channels, total_timepoints = eeg_data.shape
        print(f"ğŸ“Š æ£€æµ‹åˆ°2Dæ•°æ®: {n_channels}é€šé“, {total_timepoints}æ—¶é—´ç‚¹")
        
        # ğŸ”¥ ä½¿ç”¨n_samples_oneä¿¡æ¯æ¥åˆ†å‰²è§†é¢‘
        if n_samples_one is not None:
            print(f"ğŸ“Š æ¯ä¸ªè§†é¢‘çš„æ ·æœ¬æ•°: {n_samples_one}")
            
            if n_samples_one.ndim == 2:
                n_samples_one = n_samples_one.flatten()
            
            if len(n_samples_one) != expected_videos:
                print(f"âš ï¸ è§†é¢‘æ•°é‡ä¸åŒ¹é…: {len(n_samples_one)} != {expected_videos}")
                return None
            
            # ğŸ”¥ æ ¹æ®æ¯ä¸ªè§†é¢‘çš„æ ·æœ¬æ•°åˆ†å‰²æ•°æ®
            organized_data = []
            current_idx = 0
            
            for i, n_samples in enumerate(n_samples_one):
                n_samples = int(n_samples)
                end_idx = current_idx + n_samples
                
                if end_idx > total_timepoints:
                    print(f"âš ï¸ è§†é¢‘ {i} æ•°æ®è¶…å‡ºèŒƒå›´: {end_idx} > {total_timepoints}")
                    break
                
                # æå–è¯¥è§†é¢‘çš„æ•°æ®
                video_data = eeg_data[:, current_idx:end_idx]
                organized_data.append(video_data)
                
                print(f"ğŸ“Š è§†é¢‘ {i}: æ ·æœ¬æ•°={n_samples}, å½¢çŠ¶={video_data.shape}")
                current_idx = end_idx
            
            return organized_data
        
        else:
            # ğŸ”¥ å¹³å‡åˆ†å‰²ï¼ˆå‡è®¾æ¯ä¸ªè§†é¢‘30ç§’ï¼Œ250Hzï¼‰
            video_length = 250 * 30  # 30ç§’
            
            if total_timepoints >= expected_videos * video_length:
                organized_data = []
                for i in range(expected_videos):
                    start_idx = i * video_length
                    end_idx = start_idx + video_length
                    video_data = eeg_data[:, start_idx:end_idx]
                    organized_data.append(video_data)
                return organized_data
            else:
                print(f"âš ï¸ æ•°æ®é•¿åº¦ä¸è¶³{expected_videos}ä¸ªè§†é¢‘: {total_timepoints} < {expected_videos * video_length}")
                return None
    
    elif eeg_data.ndim == 3:
        # 3Dæ•°æ®å¤„ç†ä¿æŒä¸å˜
        print(f"ğŸ“Š æ£€æµ‹åˆ°3Dæ•°æ®: {eeg_data.shape}")
        if eeg_data.shape[0] == expected_videos:
            return [eeg_data[i] for i in range(expected_videos)]
        elif eeg_data.shape[1] == expected_videos:
            return [eeg_data[:, i, :] for i in range(expected_videos)]
        elif eeg_data.shape[2] == expected_videos:
            return [eeg_data[:, :, i] for i in range(expected_videos)]
    
    print(f"âŒ æ— æ³•è¯†åˆ«çš„EEGæ•°æ®æ ¼å¼: {eeg_data.shape}")
    return None

def extract_video_data(eeg_data_list, video_idx):
    """ä»æ•°æ®åˆ—è¡¨ä¸­æå–ç‰¹å®šè§†é¢‘çš„EEGæ•°æ®"""
    
    if isinstance(eeg_data_list, list):
        if 0 <= video_idx < len(eeg_data_list):
            return eeg_data_list[video_idx]
        else:
            print(f"âš ï¸ è§†é¢‘ç´¢å¼•è¶…å‡ºèŒƒå›´: {video_idx} >= {len(eeg_data_list)}")
            return None
    
    return None

def adjust_channels(eeg_data, target_channels=17):
    """è°ƒæ•´EEGæ•°æ®çš„é€šé“æ•°"""
    
    current_channels = eeg_data.shape[0]
    
    if current_channels == target_channels:
        return eeg_data
    elif current_channels > target_channels:
        # æˆªå–å‰target_channelsä¸ªé€šé“
        return eeg_data[:target_channels, :]
    else:
        # ç”¨é›¶å¡«å……æˆ–é‡å¤é€šé“
        padded_data = np.zeros((target_channels, eeg_data.shape[1]))
        padded_data[:current_channels, :] = eeg_data
        
        # é‡å¤æœ€åå‡ ä¸ªé€šé“å¡«å……
        if current_channels > 0:
            for i in range(current_channels, target_channels):
                padded_data[i, :] = eeg_data[i % current_channels, :]
        
        return padded_data

def get_emotion_name(video_idx):
    """æ ¹æ®æ–°çš„è§†é¢‘ç´¢å¼•è·å–æƒ…ç»ªåç§°"""
    emotion_mapping = {
        # è´Ÿé¢æƒ…ç»ª
        0: 'anger', 1: 'anger', 2: 'anger',
        3: 'disgust', 4: 'disgust', 5: 'disgust',
        6: 'fear', 7: 'fear', 8: 'fear',
        9: 'sadness', 10: 'sadness', 11: 'sadness',
        
        # æ­£é¢æƒ…ç»ª  
        12: 'amusement', 13: 'amusement', 14: 'amusement',
        15: 'inspiration', 16: 'inspiration', 17: 'inspiration',
        18: 'joy', 19: 'joy', 20: 'joy',
        21: 'tenderness', 22: 'tenderness', 23: 'tenderness',
    }
    return emotion_mapping.get(video_idx, 'unknown')

def verify_processed_data(output_dir):
    """éªŒè¯å¤„ç†åçš„æ•°æ®"""
    print(f"\nğŸ” éªŒè¯å¤„ç†åçš„æ•°æ®...")
    
    # åŠ è½½å…ƒæ•°æ®
    metadata_file = os.path.join(output_dir, 'metadata.pkl')
    if os.path.exists(metadata_file):
        with open(metadata_file, 'rb') as f:
            metadata = pickle.load(f)
        
        print(f"ğŸ“Š å…ƒæ•°æ®ä¿¡æ¯:")
        print(f"   è¢«è¯•æ•°: {len(metadata['subject_info'])}")
        print(f"   è§†é¢‘æ ·æœ¬æ•°: {len(metadata['video_info'])}")
        
        # éªŒè¯å‡ ä¸ªæ ·æœ¬æ–‡ä»¶
        sample_files = metadata['video_info'][:5]
        for info in sample_files:
            filepath = os.path.join(output_dir, info['filename'])
            if os.path.exists(filepath):
                with open(filepath, 'rb') as f:
                    data = pickle.load(f)
                print(f"âœ… {info['filename']}: EEGå½¢çŠ¶={data['eeg'].shape}, æ ‡ç­¾={data['label']}")
            else:
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {info['filename']}")

if __name__ == "__main__":
    preprocess_eeg_data()
    
    # éªŒè¯å¤„ç†ç»“æœ
    output_dir = r"E:\PyCharm Community Edition 2023.2.1\path\pypj\DAEST-main\sliced_data"
    verify_processed_data(output_dir)